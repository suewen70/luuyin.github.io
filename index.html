<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Lu Yin</title> <meta name="author" content="Lu Yin"/> <meta name="description" content=""/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/prof_pic.jpg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://luuyin.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/LUYIN.pdf">CV</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching/Supervision</a> </li> <div class="toggle-container"> <a id="light-toggle"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </a> </div> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Lu</span> Yin </h1> <p class="desc"><i> l.yin@tue.nl; luuyin@google.com</i></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/prof_pic.jpg" alt="prof_pic.jpg"> </picture> </figure> </div> <div class="clearfix"> <p>Greetings! I’m Lu, currently a researcher interning at <font color="009f06">Google's NYC office</font>. I am also serving as a Postdoctoral fellow at Eindhoven University of Technology (TU/e), located in the beautiful Netherlands.</p> <p>I hold a Ph.D. degree in the data mining group in TU/e, where I was fortunate to be supervised by the esteemed <a href="https://www.win.tue.nl/~mpechen/" target="_blank" rel="noopener noreferrer">Prof. Mykola Pechenizkiy</a> and <a href="https://vlamen.github.io/" target="_blank" rel="noopener noreferrer">Dr. Vlado Menkovski </a>. Before that, I obtained my master’s and bachelor’s degrees at the <a href="https://en.wikipedia.org/wiki/Harbin_Institute_of_Technology" target="_blank" rel="noopener noreferrer">Harbin Institute of Technology</a>.</p> <p>My research interests include model efficiency , data efficiency and knowledge elicitation and representation.</p> <p>Feel free to reach out if you’d like to discuss anything with me :)</p> </div> <div class="news"> <br> <br> <br> <h2>News</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jul, 2023</th> <td> <font color="009f06">[Intern]</font> I am joining <font color="009f06">Google's NYC office</font> as a researcher intern. </td> </tr> <tr> <th scope="row">Jun, 2023</th> <td> <font color="009f06">[Paper]</font> Two paper got accepted by <font color="009f06">ECML-PKDD 2023</font>: <font color="009f06">Robust overfitting</font>, <font color="009f06">RDebiased Sparse Training</font> </td> </tr> <tr> <th scope="row">Apr, 2023</th> <td> <font color="009f06">[Paper]</font> One paper got accepted by <font color="009f06">ICML 2023</font>: <a href="Are%20Large%20Kernels%20Better%20Teachers%20than%20Transformers%20for%20ConvNets?">Large Kernal Distillation</a> </td> </tr> <tr> <th scope="row">Mar, 2023</th> <td> <font color="009f06">[Paper]</font> Our paper <a href="https://arxiv.org/pdf/2305.19454.pdf" target="_blank" rel="noopener noreferrer">Dynamic Sparsity Is Channel-Level Sparsity Learner</a> got accepted by <a href="https://www.sparseneural.net/" target="_blank" rel="noopener noreferrer">SNN Workshop 2023</a> as <font color="009f06"> <b> Spotlight</b> </font> </td> </tr> <tr> <th scope="row">Nov, 2022</th> <td> <font color="009f06">[Paper]</font> Our paper <a href="https://arxiv.org/abs/2208.10842" target="_blank" rel="noopener noreferrer">Lottery Pools</a> got accepted by <font color="009f06">AAAI 2023</font> </td> </tr> <tr> <th scope="row">Nov, 2022</th> <td> <font color="009f06">[Paper]</font> Our paper <a href="https://arxiv.org/abs/2211.15335" target="_blank" rel="noopener noreferrer">Untrained GNNs Tickets</a> receive the <font color="009f06"> <b> Best Paper Award</b> from LoG 2022 </font> </td> </tr> <tr> <th scope="row">Sep, 2022</th> <td> <font color="009f06">[Talk]</font> I was invited to give a talk about <font color="009f06">Model/supervision Efficency</font> at <a href="https://xulabs.github.io/" target="_blank" rel="noopener noreferrer">Xu Lab</a> in <font color="009f06">Carnegie Mellon University</font> </td> </tr> <tr> <th scope="row">May, 2022</th> <td> <font color="009f06">[Paper]</font> Our paper <a href="https://arxiv.org/abs/2205.15322" target="_blank" rel="noopener noreferrer">Sup-tickets sparse training</a> got accepted by <font color="009f06">UAI 2022</font> </td> </tr> <tr> <th scope="row">Mar, 2022</th> <td> <font color="009f06">[Paper]</font> Our paper is accpeted by <font color="009f06">IDA 2022</font> , which was also the first conference (symposium) that I have attended in the first year of my PhD. Life is like a cycle <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"> </td> </tr> </table> </div> </div> <div class="publications"> <h2>Selected Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">UAI</abbr></div> <div id="yin2022superposing" class="col-sm-8"> <div class="title">Superposing Many Tickets into One: A Performance Booster for Sparse Neural Network Training</div> <div class="author"> <b>Yin, Lu</b>; Menkovski, Vlado; Fang, Meng; Huang, Tianjin; Pei, Yulong; Pechenizkiy, Mykola; Mocanu, Decebal Constantin; and Liu, Shiwei </div> <div class="periodical"> <em>In The 38th Conference on Uncertainty in Artificial Intelligence</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=HeZlJPLoqgq" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/Superposing_Many_Tickets_into_One__UAI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Recent works on sparse neural network training (sparse training) have shown that a compelling trade-off between performance and efficiency can be achieved by training intrinsically sparse neural networks from scratch. Existing sparse training methods usually strive to find the best sparse subnetwork possible in one single run, without involving any expensive dense or pre-training steps. For instance, dynamic sparse training (DST), as one of the most prominent directions, is capable of reaching a competitive performance of dense training by iteratively evolving the sparse topology during the course of training. In this paper, we argue that it is better to allocate the limited resources to create multiple low-loss sparse subnetworks and superpose them into a stronger one, instead of allocating all resources entirely to find an individual subnetwork. To achieve this, two desiderata are required: (1) efficiently producing many low-loss subnetworks, the so-called cheap tickets, within one training process limited to the standard training time used in dense training; (2) effectively superposing these cheap tickets into one stronger subnetwork without going over the constrained parameter budget. To corroborate our conjecture, we present a novel sparse training approach, termed Sup-tickets, which can satisfy the above two desiderata concurrently in a single sparse-to-sparse training process. Across various modern architectures on CIFAR-10/100 and ImageNet, we show that Sup-tickets integrates seamlessly with the existing sparse training methods and demonstrates consistent performance improvement. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div> <div id="yin2022lottery" class="col-sm-8"> <div class="title">Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost</div> <div class="author"> <b>Yin, Lu</b>; Liu, Shiwei; Fang, Meng; Huang, Tianjin; Menkovski, Vlado; and Pechenizkiy, </div> <div class="periodical"> <em>In Thirty-Seventh AAAI Conference on Artificial Intelligence</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2208.10842.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/Lottery%20Pools.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Lottery tickets (LTs) is able to discover accurate and sparse subnetworks that could be trained in isolation to match the performance of dense networks. Ensemble, in parallel, is one of the oldest time-proven tricks in machine learning to improve performance by combining the output of multiple independent models. However, the benefits of ensemble in the context of LTs will be diluted since ensemble does not directly lead to stronger sparse subnetworks, but leverages their predictions for a better decision. In this work, we first observe that directly averaging the weights of the adjacent learned subnetworks significantly boosts the performance of LTs. Encouraged by this observation, we further propose an alternative way to perform an ’ensemble’ over the subnetworks identified by iterative magnitude pruning via a simple interpolating strategy. We call our method Lottery Pools. In contrast to the naive ensemble which brings no performance gains to each single subnetwork, Lottery Pools yields much stronger sparse subnetworks than the original LTs without requiring any extra training or inference cost. Across various modern architectures on CIFAR-10/100 and ImageNet, we show that our method achieves significant performance gains in both, in-distribution and out-of-distribution scenarios. Impressively, evaluated with VGG-16 and ResNet-18, the produced sparse subnetworks outperform the original LTs by up to 1.88% on CIFAR-100 and 2.36% on CIFAR-100-C; the resulting dense network surpasses the pre-trained dense-model up to 2.22% on CIFAR-100 and 2.38% on CIFAR-100-C. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div> <div id="liu2021we" class="col-sm-8"> <div class="title">Do we actually need dense over-parameterization? in-time over-parameterization in sparse training</div> <div class="author">Liu, Shiwei; <b>Yin, Lu</b>; Mocanu, Decebal Constantin; and Pechenizkiy, Mykola </div> <div class="periodical"> <em>In International Conference on Machine Learning</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://proceedings.mlr.press/v139/liu21y/liu21y.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/Do%20We%20Actually%20Need%20Dense%20Over-Parameterization.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this paper, we introduce a new perspective on training deep neural networks capable of state-of-the-art performance without the need for the expensive over-parameterization by proposing the concept of In-Time Over-Parameterization (ITOP) in sparse training. By starting from a random sparse network and continuously exploring sparse connectivities during training, we can perform an Over-Parameterization over the course of training, closing the gap in the expressibility between sparse training and dense training. We further use ITOP to understand the underlying mechanism of Dynamic Sparse Training (DST) and discover that the benefits of DST come from its ability to consider across time all possible parameters when searching for the optimal sparse connectivity. As long as sufficient parameters have been reliably explored, DST can outperform the dense neural network by a large margin. We present a series of experiments to support our conjecture and achieve the state-of-the-art sparse training performance with ResNet-50 on ImageNet. More impressively, ITOP achieves dominant performance over the overparameterization-based sparse methods at extreme sparsities. When trained with ResNet-34 on CIFAR-100, ITOP can match the performance of the dense model at an extreme sparsity 98%.</p> </div> </div> </div> </li> </ol> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECML</abbr></div> <div id="yin2020knowledge" class="col-sm-8"> <div class="title">Knowledge Elicitation Using Deep Metric Learning and Psychometric Testing</div> <div class="author"> <b>Yin, Lu</b>; Menkovski, Vlado; and Pechenizkiy, Mykola </div> <div class="periodical"> <em>In Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em> 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2004.06353.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/Knowledge%20Elicitation%20using%20Deep%20Metric%20Learning%20and%20Psychometric%20Testing.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Knowledge present in a domain is well expressed as relationships between corresponding concepts. For example, in zoology, animal species form complex hierarchies; in genomics, the different (parts of) molecules are organized in groups and subgroups based on their functions; plants, molecules, and astronomical objects all form complex taxonomies. Nevertheless, when applying supervised machine learning (ML) in such domains, we commonly reduce the complex and rich knowledge to a fixed set of labels, and induce a model shows good generalization performance with respect to these labels. The main reason for such a reductionist approach is the difficulty in eliciting the domain knowledge from the experts. Developing a label structure with sufficient fidelity and providing comprehensive multi-label annotation can be exceedingly labor-intensive in many real-world applications. In this paper, we provide a method for efficient hierarchical knowledge elicitation (HKE) from experts working with high-dimensional data such as images or videos. Our method is based on psychometric testing and active deep metric learning. The developed models embed the high-dimensional data in a metric space where distances are semantically meaningful, and the data can be organized in a hierarchical structure. We provide empirical evidence with a series of experiments on a synthetically generated dataset of simple shapes, and Cifar 10 and Fashion-MNIST benchmarks that our method is indeed successful in uncovering hierarchical structures.</p> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6C.%79%69%6E@%74%75%65.%6E%6C" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=G4Xe1NkAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/luuyin" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://twitter.com/luu_yinn" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> Please feel free to contact me :) </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Those who can imagine anything, can create the impossible ― Alan Turing </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>